{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Strategy for optimizing the Real Time depth estimation and battery optimization\n",
        "\n",
        "####1. Use a Lightweight Depth Model\n",
        "*   Uses MiDaS (DPT_Hybrid) for depth estimation (reasonably accurate and lightweight)\n",
        "\n",
        "####2. Skip Frames\n",
        "*   Estimating depth every N frames and Using optical flow to propagate in-between. Tune FRAME_SKIP dynamically: slow it down when robot is idle or background is static.\n",
        "*   Cuts AI inference time by ~80%. Consider running AI every 10 frames if flow is stable.\n",
        "\n",
        "####3. Optical Flow\n",
        "*   Maintains temporal coherence.\n",
        "\n",
        "####4. EMA filtering\n",
        "*   Applies temporal smoothing, even with good models, monocular depth is noisy.This stabilizes jitter and produce consistent output with less frequent AI inference.\n",
        "\n",
        "####5. Low res inference\n",
        "*   Fast, barely affects visual quality\n",
        "\n",
        "These techniques keeps the system efficient for real-time use with just a webcam."
      ],
      "metadata": {
        "id": "I_n9St4_wRDD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N4EbSwpswMgM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Configurations"
      ],
      "metadata": {
        "id": "FUy6zknJzOBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FRAME_SKIP = 5  # Estimate depth every N frames\n",
        "TEMPORAL_ALPHA = 0.9  # For exponential moving average filtering\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_GPU else \"cpu\")\n",
        "DEPTH_MODEL_TYPE = \"DPT_Hybrid\"  # Light but decent quality"
      ],
      "metadata": {
        "id": "CW_vtg4nzKXb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load MiDAS Depth Estimation model"
      ],
      "metadata": {
        "id": "Pg0lMLv0zTE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "midas = torch.hub.load(\"intel-isl/MiDaS\", DEPTH_MODEL_TYPE)\n",
        "midas.to(DEVICE).eval()"
      ],
      "metadata": {
        "id": "XcwIykFBzVWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load the corresponding transforms"
      ],
      "metadata": {
        "id": "XjeW7m_FzdkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "transform = midas_transforms.dpt_transform if DEPTH_MODEL_TYPE.startswith(\"DPT\") else midas_transforms.small_transform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN8N0wmSzd8S",
        "outputId": "50ffc2e6-d4bd-4457-d676-98ebf932d70a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Depth Estimation module"
      ],
      "metadata": {
        "id": "OiKx6tJwzq6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_depth_midas(frame):\n",
        "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    input_tensor = transform(img_rgb).to(DEVICE).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_tensor)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=img_rgb.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze()\n",
        "        depth_map = prediction.cpu().numpy()\n",
        "\n",
        "    return depth_map"
      ],
      "metadata": {
        "id": "AbQZwn1JzpHZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Propagate depth optical flow"
      ],
      "metadata": {
        "id": "KDt-Gab0zuHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def propagate_depth_optical_flow(prev_gray, curr_gray, prev_depth):\n",
        "    flow = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None,\n",
        "                                        pyr_scale=0.5, levels=3, winsize=15,\n",
        "                                        iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
        "\n",
        "    h, w = flow.shape[:2]\n",
        "    flow_map_x, flow_map_y = np.meshgrid(np.arange(w), np.arange(h), indexing='xy')\n",
        "    remap_x = (flow_map_x + flow[..., 0]).astype(np.float32)\n",
        "    remap_y = (flow_map_y + flow[..., 1]).astype(np.float32)\n",
        "\n",
        "    warped_depth = cv2.remap(prev_depth, remap_x, remap_y,\n",
        "                             interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
        "\n",
        "    return warped_depth"
      ],
      "metadata": {
        "id": "tq3pJXLbz0Zy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Temporal Filtering"
      ],
      "metadata": {
        "id": "bvkyBPUuz3MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_temporal_filter(new_depth, prev_filtered):\n",
        "    return TEMPORAL_ALPHA * prev_filtered + (1 - TEMPORAL_ALPHA) * new_depth"
      ],
      "metadata": {
        "id": "BoaUtELAz3Wb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Main method"
      ],
      "metadata": {
        "id": "t4VZlLwU0MmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "frame_count = 0\n",
        "prev_gray = None\n",
        "prev_depth = None\n",
        "filtered_depth = None\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert to grayscale for optical flow\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Decide whether to run full depth estimation or warp\n",
        "    if frame_count % FRAME_SKIP == 0 or prev_depth is None:\n",
        "        depth_map = estimate_depth_midas(frame)\n",
        "        prev_depth = depth_map\n",
        "    else:\n",
        "        depth_map = propagate_depth_optical_flow(prev_gray, gray, prev_depth)\n",
        "\n",
        "    # Apply temporal smoothing\n",
        "    if filtered_depth is None:\n",
        "        filtered_depth = depth_map\n",
        "    else:\n",
        "        filtered_depth = apply_temporal_filter(depth_map, filtered_depth)\n",
        "\n",
        "    # Normalize for display\n",
        "    depth_vis = cv2.normalize(filtered_depth, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    depth_vis = np.uint8(depth_vis)\n",
        "    depth_color = cv2.applyColorMap(depth_vis, cv2.COLORMAP_INFERNO)\n",
        "\n",
        "    # Display\n",
        "    cv2.imshow(\"Real-Time Depth Map\", depth_color)\n",
        "\n",
        "    # Update state\n",
        "    prev_gray = gray\n",
        "    prev_depth = depth_map\n",
        "    frame_count += 1\n",
        "\n",
        "    # Break on key\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# clean up\n",
        "# cap.release()\n",
        "# cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "AQXOnLwoz-cR"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}
